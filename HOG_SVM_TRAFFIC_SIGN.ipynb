{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-class (Nonlinear) SVM Example\n",
    "--------------------------------\n",
    "\n",
    "This function wll illustrate how to implement the gaussian kernel with multiple classes on the iris dataset.\n",
    "\n",
    "Gaussian Kernel:\n",
    "\n",
    "$$K(x_1, x_2) = e^{-\\gamma \\cdot (x_1 - x_2)^2}$$\n",
    "\n",
    "X : (Sepal Length, Petal Width)\n",
    "\n",
    "Y: (I. setosa, I. virginica, I. versicolor) (3 classes)\n",
    "\n",
    "Basic idea: introduce an extra dimension to do one vs all classification.\n",
    "\n",
    "The prediction of a point will be the category with the largest margin or distance to boundary.\n",
    "\n",
    "We start by loading the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn import datasets\n",
    "from tensorflow.python.framework import ops\n",
    "ops.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3781\n"
     ]
    }
   ],
   "source": [
    "X = data.iloc[:,:3781]\n",
    "y = data.iloc[:,3781]\n",
    "y = np.array(y).reshape([-1,1])\n",
    "\n",
    "num_classes = np.max(y)\n",
    "min_in_y = np.min(y)\n",
    "# print(num_classes)\n",
    "# print(min_in_y)\n",
    "# print(y[2069,0])\n",
    "\n",
    "y_vals = []\n",
    "\n",
    "for i in range((int)(num_classes)):\n",
    "    y_t = np.zeros((1,y.shape[0]))\n",
    "    y_t[:] = -1\n",
    "    indices = np.where(y == (i+1))\n",
    "\n",
    "    y_t[0,indices[0]] = 1\n",
    "    y_vals.append(y_t)\n",
    "y_vals = np.array(y_vals).reshape([(int)(num_classes),y.shape[0]])\n",
    "x_vals = np.array(X)\n",
    "print(x_vals.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start a computational graph session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we load the iris data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "# iris.data = [(Sepal Length, Sepal Width, Petal Length, Petal Width)]\n",
    "# iris = datasets.load_iris()\n",
    "# x_vals = np.array([[x[0], x[3]] for x in iris.data])\n",
    "# y_vals1 = np.array([1 if y==0 else -1 for y in iris.target])\n",
    "# y_vals2 = np.array([1 if y==1 else -1 for y in iris.target])\n",
    "# y_vals3 = np.array([1 if y==2 else -1 for y in iris.target])\n",
    "# y_vals = np.array([y_vals1, y_vals2, y_vals3])\n",
    "# print(y_vals.shape)\n",
    "# print(x_vals.shape)\n",
    "# class1_x = [x[0] for i,x in enumerate(x_vals) if iris.target[i]==0]\n",
    "# class1_y = [x[1] for i,x in enumerate(x_vals) if iris.target[i]==0]\n",
    "# class2_x = [x[0] for i,x in enumerate(x_vals) if iris.target[i]==1]\n",
    "# class2_y = [x[1] for i,x in enumerate(x_vals) if iris.target[i]==1]\n",
    "# class3_x = [x[0] for i,x in enumerate(x_vals) if iris.target[i]==2]\n",
    "# class3_y = [x[1] for i,x in enumerate(x_vals) if iris.target[i]==2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declare the batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize placeholders and create the variables for multiclass SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_features = x_vals.shape[1]\n",
    "num_classes = (int)(num_classes)\n",
    "\n",
    "# Initialize placeholders\n",
    "x_data = tf.placeholder(shape=[None, num_features], dtype=tf.float32)\n",
    "y_target = tf.placeholder(shape=[num_classes, None], dtype=tf.float32)\n",
    "prediction_grid = tf.placeholder(shape=[None, num_features], dtype=tf.float32)\n",
    "\n",
    "# Create variables for svm\n",
    "b = tf.Variable(tf.random_normal(shape=[num_classes,batch_size]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the Gaussian Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Gaussian (RBF) kernel\n",
    "gamma = tf.constant(-10.0)\n",
    "dist = tf.reduce_sum(tf.square(x_data), 1)\n",
    "dist = tf.reshape(dist, [-1,1])\n",
    "sq_dists = tf.multiply(2., tf.matmul(x_data, tf.transpose(x_data)))\n",
    "my_kernel = tf.exp(tf.multiply(gamma, tf.abs(sq_dists)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declare a function that will do reshaping and batch matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Declare function to do reshape/batch multiplication\n",
    "def reshape_matmul(mat, _size):\n",
    "    v1 = tf.expand_dims(mat, 1)\n",
    "    v2 = tf.reshape(v1, [num_classes, _size, 1])\n",
    "    return(tf.matmul(v2, v1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can compute the SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute SVM Model\n",
    "first_term = tf.reduce_sum(b)\n",
    "b_vec_cross = tf.matmul(tf.transpose(b), b)\n",
    "y_target_cross = reshape_matmul(y_target, batch_size)\n",
    "\n",
    "second_term = tf.reduce_sum(tf.multiply(my_kernel, tf.multiply(b_vec_cross, y_target_cross)),[1,2])\n",
    "loss = tf.reduce_sum(tf.negative(tf.subtract(first_term, second_term)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the same RBF kernel for a set of prediction points (used on a grid of points at the end)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Gaussian (RBF) prediction kernel\n",
    "rA = tf.reshape(tf.reduce_sum(tf.square(x_data), 1),[-1,1])\n",
    "rB = tf.reshape(tf.reduce_sum(tf.square(prediction_grid), 1),[-1,1])\n",
    "pred_sq_dist = tf.add(tf.subtract(rA, tf.multiply(2., tf.matmul(x_data, tf.transpose(prediction_grid)))), tf.transpose(rB))\n",
    "pred_kernel = tf.exp(tf.multiply(gamma, tf.abs(pred_sq_dist)))\n",
    "\n",
    "prediction_output = tf.matmul(tf.multiply(y_target,b), pred_kernel)\n",
    "prediction = tf.argmax(prediction_output-tf.expand_dims(tf.reduce_mean(prediction_output,1), 1), 0)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(prediction, tf.argmax(y_target,0)), tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the optimization and variable initializer operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare optimizer\n",
    "my_opt = tf.train.AdamOptimizer(0.005)\n",
    "train_step = my_opt.minimize(loss)\n",
    "\n",
    "# Initialize variables\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now start the training loop for the multiclass SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "Step #1\n",
      "Loss = -128165.68390625\n",
      "25\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "Step #2\n",
      "Loss = -348665.78\n",
      "25\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "Step #3\n",
      "Loss = -569165.8675\n",
      "25\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "Step #4\n",
      "Loss = -789665.9925\n",
      "25\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "Step #5\n",
      "Loss = -1010166.29\n",
      "25\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "Step #6\n",
      "Loss = -1230666.59\n",
      "25\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "Step #7\n",
      "Loss = -1451167.06\n",
      "25\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "Step #8\n",
      "Loss = -1671667.615\n",
      "25\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "Step #9\n",
      "Loss = -1892168.19\n",
      "25\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "Step #10\n",
      "Loss = -2112669.095\n",
      "25\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "Step #11\n",
      "Loss = -2333170.09\n",
      "25\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "Step #12\n",
      "Loss = -2553671.28\n",
      "25\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "Step #13\n",
      "Loss = -2774172.8\n",
      "25\n",
      "(1000, 3781)\n",
      "(42, 1000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "Step #14\n",
      "Loss = -2994674.47\n",
      "25\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "Step #15\n",
      "Loss = -3215176.28\n",
      "25\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "Step #16\n",
      "Loss = -3435678.42\n",
      "25\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "Step #17\n",
      "Loss = -3656181.01\n",
      "25\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "Step #18\n",
      "Loss = -3876683.6\n",
      "25\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "Step #19\n",
      "Loss = -4097186.72\n",
      "25\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "(1000, 3781)\n",
      "(42, 1000)\n",
      "Step #20\n",
      "Loss = -4317689.78\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "loss_vec = []\n",
    "batch_accuracy = []\n",
    "for i in range(20):\n",
    "    num_batches = (int)(x_vals.shape[0]/batch_size)\n",
    "    print(num_batches)\n",
    "    t_loss = 0.0\n",
    "    t_acc = 0.0\n",
    "    \n",
    "    for j in range(num_batches):\n",
    "        rand_x = x_vals[j*batch_size:(j+1)*batch_size,:]\n",
    "        rand_y = y_vals[:,j*batch_size:(j+1)*batch_size]\n",
    "        print(rand_x.shape)\n",
    "        print(rand_y.shape)\n",
    "    # rand_index = np.random.choice(len(x_vals), size=batch_size)\n",
    "    # rand_x = x_vals[rand_index]\n",
    "    # rand_y = y_vals[:,rand_index]\n",
    "        sess.run(train_step, feed_dict={x_data: rand_x, y_target: rand_y})\n",
    "#         print(\"HOLA\")\n",
    "        temp_loss = sess.run(loss, feed_dict={x_data: rand_x, y_target: rand_y})\n",
    "        t_loss+=temp_loss\n",
    "        acc_temp = sess.run(accuracy, feed_dict={x_data: rand_x,\n",
    "                                                 y_target: rand_y,\n",
    "                                                 prediction_grid:rand_x})\n",
    "        t_acc+=acc_temp\n",
    "    \n",
    "    t_loss/=(num_batches*1.0)\n",
    "    t_acc/=(num_batches*1.0)\n",
    "    \n",
    "    loss_vec.append(t_loss)\n",
    "    batch_accuracy.append(t_acc)\n",
    "    \n",
    "    print('Step #' + str(i+1))\n",
    "    print('Loss = ' + str(t_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a pretty picture, to see the results, we create a fine grid of points to label/color for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a mesh to plot points in\n",
    "# x_min, x_max = x_vals[:, 0].min() - 1, x_vals[:, 0].max() + 1\n",
    "# y_min, y_max = x_vals[:, 1].min() - 1, x_vals[:, 1].max() + 1\n",
    "# xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.02),\n",
    "#                      np.arange(y_min, y_max, 0.02))\n",
    "# grid_points = np.c_[xx.ravel(), yy.ravel()]\n",
    "# grid_predictions = sess.run(prediction, feed_dict={x_data: rand_x,\n",
    "#                                                    y_target: rand_y,\n",
    "#                                                    prediction_grid: grid_points})\n",
    "# grid_predictions = grid_predictions.reshape(xx.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot points and grid\n",
    "# plt.contourf(xx, yy, grid_predictions, cmap=plt.cm.Paired, alpha=0.8)\n",
    "# plt.plot(class1_x, class1_y, 'ro', label='I. setosa')\n",
    "# plt.plot(class2_x, class2_y, 'kx', label='I. versicolor')\n",
    "# plt.plot(class3_x, class3_y, 'gv', label='I. virginica')\n",
    "# plt.title('Gaussian SVM Results on Iris Data')\n",
    "# plt.xlabel('Pedal Length')\n",
    "# plt.ylabel('Sepal Width')\n",
    "# plt.legend(loc='lower right')\n",
    "# plt.ylim([-0.5, 3.0])\n",
    "# plt.xlim([3.5, 8.5])\n",
    "# plt.show()\n",
    "\n",
    "# # Plot batch accuracy\n",
    "# plt.plot(batch_accuracy, 'k-', label='Accuracy')\n",
    "# plt.title('Batch Accuracy')\n",
    "# plt.xlabel('Generation')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.legend(loc='lower right')\n",
    "# plt.show()\n",
    "\n",
    "# # Plot loss over time\n",
    "# plt.plot(loss_vec, 'k-')\n",
    "# plt.title('Loss per Generation')\n",
    "# plt.xlabel('Generation')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZsAAAD8CAYAAAChHgmuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngFPYiIhIwClsREQk4P4/2KaTZYTl800AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3Xl8VPW9//HXh0DYCfu+BMK+iEBY\nxB1QwQVsa1t3QCrSirZ6tVq322J/91ap3a5erbYorqgIihSLS9W2WjUJW9hJ2LJBgIQAIZBk5vv7\nYwZvGgMMkMmZ5f18PPLInDnfzHw4nHnn5Hu+33PMOYeIiMSWel4XICIitU/hLiISgxTuIiIxSOEu\nIhKDFO4iIjFI4S4iEoMU7iIiMUjhLiISgxTuIiIxqL5Xb9y2bVuXnJzs1duLiESljIyMvc65didr\n51m4Jycnk56e7tXbi4hEJTPbEUo7dcuIiMQghbuISAxSuIuIxCCFu4hIDFK4i4jEIIW7iEgMUriL\niMQgz8a5i4jEi6OVPrbtLSWr8BBZhYcY378DQ7omhfU9Fe4iIrXk4JEKsvcEQnxL4UGyg2G+s+gw\n/uDtqs2gTbOGCncRkUjinGPvofLAUfieQ18HeFbhIXYdOPJ1uwYJRnKbpgzo1IKrhnamd/tmpLQL\nfDVOTAh7nQp3EZHj8PsdO4sOk5lXwtr8EtblHWBdfgnFhyu+btM0MYGU9s0Ym9KGlPbN6B386t66\nCQ0SvDutqXAXEQF8fse2vYdYm3cgEOZ5JazPP8DBo5UAJCbUo1/H5lw2qCN9OzT/OsQ7JTXCzDyu\n/psU7iISdyp8frIKD7E2GOJr8w+wPv8AZRU+ABrWr8eATi24elgXBndpwaDOSfTt0JzE+tEzwDCk\ncDezicDvgQTgT865X1VbPw2YC+QFn3rSOfenWqxTROS0FR48Qsb2YtK2F5Oxs5gNBQcor/QD0CQx\ngUGdW/D9kd0Y3CWJIV2SSGnXlPoedqnUhpOGu5klAE8BlwC5QJqZLXHOra/W9HXn3Oww1CgiEjK/\n35G95xBp24tJ31FE+vZidhYdBgJH5EO7tmTqOT0Y3CWJQZ2T6Nm2KQn1Iq9b5UyFcuQ+Cshyzm0F\nMLMFwBSgeriLiNS5IxU+1uSWfB3kGTuKKSkLnPBs0zSRET1acdOYHoxIbsXgzklR1bVyJkIJ9y5A\nTpXlXGB0De2+Y2YXAJuBu5xzOTW0ERE5I0Wl5aRvLyJjRzFp24tYm3eAcl+giyWlXVMmDurIiORW\njExuTXKbJhF5srMuhBLuNW0ZV235XeA159xRM5sFzAfGfeOFzGYCMwG6d+9+iqWKSDwqKavgq21F\nfJ69l39l72PjroNAYPTKkK5JTD83mdTk1ozo0YrWTRM9rjZyhBLuuUC3KstdgfyqDZxz+6osPgc8\nVtMLOeeeBZ4FSE1Nrf4LQkSEsnIf6TuK+Dx7H59n7SUzrwS/C/SXj0xuzb2XdWZUz9YM6ZJEowbh\nnwwUrUIJ9zSgj5n1JDAa5lrg+qoNzKyTc64guDgZ2FCrVYpIzCqv9LMqZz+fZ+/l8+x9rNxZTIXP\nUb+eMax7S2aP68PYlDYM696ShvUV5qE6abg75yrNbDawnMBQyHnOuXVmNgdId84tAe40s8lAJVAE\nTAtjzSISxXx+x9q8ksCRefZe0rcXU1bhwwyGdEnilvN6MjalLak9WtG0oabinC5zzpvekdTUVJee\nnu7Je4tI3So5XMEnmwv5cEMhn24q5MCRwKzPvh2aMTalLeektGFMzzYkNWngcaWRz8wynHOpJ2un\nX4siEhbb9pby0YbdfLhhN2nbi/H5HW2bJXLZoI6c37cd5/RqQ7vmDb0uM2Yp3EWkVlT6/KzYuf/r\nQM/eUwpAvw7NmXVhL8YP6MDZXVtSLwYnDEUihbuInLaDRyr4++a9fLRhNx9vKqT4cAUNEowxvdpw\n05gejB/QgW6tm3hdZlxSuIvIKckpOsxHG3bz0cZCvti6jwqfo2WTBozr157xAzpwQd+2NG+kvnOv\nKdxF5KR27CvlL5kFvJe5i8y8EiAwG/SWc3syfkAHhndvGfUX2oo1CncRqdG2vaUsyyxgWWYB6/IP\nADC0W0t+Nqk/lw7qSM+2TT2uUE5E4S4iX8vec4hlawpYtnYXGwoCgT6se0seumIAEwd3pGsr9Z9H\nC4W7SJzLKjzIX9bsYllmAZt2B67bMqJHKx6+ciCTBnekc8vGHlcop0PhLhKHNu8+yF/WBLpcthQe\nwgxSe7TikSsHMmlIRzolKdCjncJdJE4UlJSxaEUei1fmkRUM9JHJrfn5VQOZNKQTHVo08rpEqUUK\nd5EYdqTCx/J1u1iYkcs/s/biHIxMbsWcKYOYOKgj7RXoMUvhLhJjnHOs2LmfhRm5LF2dz8GjlXRp\n2Zg7Lu7Nt4d3JVmjXOKCwl0kRuTvL2PxyjwWZuSybW8pjRrU4/LBnbhmRFfG9Gqjaf9xRuEuEsXK\nyn28v/7fu11G9WzNDy9MYdKQjpopGscU7iJRxjlHxo5i3lqRy9LVBf/X7TKuD98Z3oUebdTtIgp3\nkahxpMLHm+k5PP/ZdrbuLaVxgwQmDekY6HbpqW4X+XcKd5EIV3K4gpe+2M7zn21nX2k5Q7u15PFr\nzuLyIZ1opjsVyXFozxCJULtKjvDnf27l1S93Ulru48K+7fjhRSmM7tkaMx2ly4kp3EUiTFbhIZ79\nezaLV+bh8zuuGtqZ2y5IYWDnFl6XJlFE4S4SIVbuLOaZT7N5f/1uEhPqcd2o7tx6fi/d7EJOi8Jd\nxEPOOT7dvIenP8nmy21FJDVuwOyLezN1bDJtm+n+onL6FO4iHqj0+flLZgHPfLqVDQUH6NiiEQ9d\nMYBrR3XXSVKpFdqLROrQseGMz/5jKzlFZaS0a8rca85iytldSKyvOxlJ7VG4i9SBSp+fRSvz+P2H\nW8jbX8aw7i15+IqBTBjQQePTJSwU7iJh5Jxj+bpdzF2+iew9pQztmsRj3zmLc3u30XBGCSuFu0iY\nfJa1l8f/upHVuSX0bt+MZ24czmWDOirUpU4o3EVq2eqc/Ty+fCOfZe2jS8vGPH7NWXx7WBfqJ6hP\nXeqOwl2klmQVHuTXyzfz13W7aN00kUeuHMgNY7rTsH6C16VJHFK4i5yhvP1l/O6Dzby1IpcmifW5\na0JfZpzfU0MaxVPa+0RO095DR3nq4yxe+WInGNxybk9+dHFvWjdN9Lo0EYW7yKk6eKSC5/6xjT//\nYytlFT6+O6IbP57Qh84tG3tdmsjXQgp3M5sI/B5IAP7knPvVcdpdA7wJjHTOpddalSIRwDnHwoxc\n/vu9jRSVlnP5kI7cfUk/erdv5nVpIt9w0nA3swTgKeASIBdIM7Mlzrn11do1B+4EvgxHoSJeyik6\nzAOLM/nHlr2k9mjFC9NHclbXll6XJXJcoRy5jwKynHNbAcxsATAFWF+t3aPA48A9tVqhiId8fsfz\nn23jifc3U8/g0SmDuGF0D80qlYgXSrh3AXKqLOcCo6s2MLNhQDfn3FIzU7hLTNi46wD3vZXJ6pz9\njOvfnl9ePVj96hI1Qgn3mg5R3NcrzeoBvwWmnfSFzGYCMwG6d+8eWoUidexopY8n/5bF059k06Jx\nA35/7dlMHtpZM0slqoQS7rlAtyrLXYH8KsvNgcHAJ8GdvyOwxMwmVz+p6px7FngWIDU11SESYTJ2\nFHHfW5lkFR7iW8O68PCVAzW0UaJSKOGeBvQxs55AHnAtcP2xlc65EqDtsWUz+wS4R6NlJJocOlrJ\n3L9u5MUvdtA5qTHPTx/Jxf3ae12WyGk7abg75yrNbDawnMBQyHnOuXVmNgdId84tCXeRIuH08aZC\nHlyUScGBI0w9J5l7Luun2aUS9ULag51zy4Bl1Z575DhtLzrzskTCb9+hozy6dD1vr8qnd/tmLJw1\nlhE9Wnldlkit0OGJxB3nHO+symfO0vUcPFLBneP7cPvFKbrAl8QUhbvElYKSMh5YlMnHm/YwtFtL\nHv/OWfTr2NzrskRqncJd4oJzjkUr8vj5u+uo9DkevnIg08Ymk6DJSBKjFO4S8/YcPMoDizP5YP1u\nUnu04tffHUpy26ZelyUSVgp3iWl/WVPAQ29nUlru48HLB3DLeT11tC5xQeEuMam4tJyH31nL0jUF\nDO2axBPfG0rv9upbl/ihcJeY88H63fxsUSYlZeXcc2lfZl2YovuXStxRuEvMOHCkgjnvrmdhRi79\nOzbnxVtGMbBzC6/LEvGEwl1iwt837+G+t9ZQePAod4zrzR3j+pBYX0frEr8U7hLVSo9W8l/LNvDK\nlzvp3b4Zi24cwdBuuomGiMJdotYXW/dx78LV5BaXMfOCXtx9SV8aNdAsUxFQuEsUOlLh4/G/buL5\nz7fRvXUT3rjtHEYmt/a6LJGIonCXqLJl90FuezmDrXtKufmcHtw/qT9NErUbi1SnT4VEjbTtRcx4\nIY2GDRJ45QejObd325P/kEicUrhLVFi+bhd3vraSLq0aM3/6KLq1buJ1SSIRTeEuEe/lL3bwyDtr\nOatrS+ZNG6nb3omEQOEuEcs5x28/2Mwf/pbFuP7tefL6YepfFwmRPikSkSp9fh5cvJbX03P4XmpX\n/utbQ3QJAZFToHCXiFNW7mP2qyv4aGMhd4zrzd2X9MVMV3IUORUKd4koxaXl3DI/jVU5+3n06sHc\nNKaH1yWJRCWFu0SM3OLD3DzvK3KLy3j6huFMHNzJ65JEopbCXSLChoIDTJ33FUcqfLw8YzSjemrG\nqciZULiL5/6VvY+ZL6bTtGF93pw1VjesFqkFCnfx1NI1+dz9+mp6tGnC/FtG0bllY69LEokJCnfx\nzAufbeMXS9eT2qMVz92cSssmmpwkUlsU7lLnnHM8vnwTT3+SzaUDO/CH64bpUr0itUzhLnWqwufn\nvrfWsGhFHjeM7s6cKYNJqKcx7CK1TeEudabC5+fO11by3tpd3H1JX+4Y11uTk0TCROEudaLC5+fH\nCwLB/vCVA5lxXk+vSxKJabpYh4Rdpc/PTxasYlnmLh66YoCCXaQOKNwlrCp9fn7y+ir+klnAg5cP\n4Afn9/K6JJG4EFK4m9lEM9tkZllmdn8N62eZWaaZrTKzf5rZwNovVaJNpc/PXW+sZumaAh64vD+3\nXqBgF6krJw13M0sAngImAQOB62oI71edc0Occ2cDjwO/qfVKJapU+vzc/cZq3l2dz/2T+jPzghSv\nSxKJK6EcuY8CspxzW51z5cACYErVBs65A1UWmwKu9kqUaOPzO/7jzdUsWZ3PTyf2Y9aFCnaRuhbK\naJkuQE6V5VxgdPVGZnY7cDeQCIyr6YXMbCYwE6B79+6nWqtEAZ/fcc+bq3lnVT73XtaPH13U2+uS\nROJSKEfuNQ1E/saRuXPuKedcCnAf8FBNL+Sce9Y5l+qcS23Xrt2pVSoRz+d33PvmahavzOOeS/ty\n+8UKdhGvhBLuuUC3KstdgfwTtF8AXH0mRUn08fkdP124hkUr8/iPS/oye1wfr0sSiWuhhHsa0MfM\neppZInAtsKRqAzOr+km+AthSeyVKpPP7Hfe9tYa3VuRy14S+3DFewS7itZP2uTvnKs1sNrAcSADm\nOefWmdkcIN05twSYbWYTgAqgGJgazqIlchwL9oUZufx4fB9+PEHBLhIJQrr8gHNuGbCs2nOPVHn8\n41quS6KA3+/42aJM3szI5c7xfbjrkr5elyQiQZqhKqfF73c8sDiT19NzuGNcb+7SEbtIRFG4yynz\n+x0Pvp3JgrQcbr84hbsv6aurO4pEGIW7nBK/3/HQO2t57ascfnRRCvdc2k/BLhKBFO5ySua+v4lX\nv9zJrAtTuPcyBbtIpFK4S8jeSMvh6U+yuW5Ud+6bqGAXiWQKdwnJ59l7eWBxJuf3acucKYMU7CIR\nTuEuJ5VVeIhZL2XQs21Tnrx+OA0StNuIRDp9SuWEikrLueWFNBok1GPetJEkNW7gdUkiEgLdQ1WO\n62ilj5kvprPrwBEWzBxDt9ZNvC5JREKkI3epkXOBC4Gl7yjmie8OZXj3Vl6XJCKnQOEuNfr9R1t4\nZ1U+91zal6uGdva6HBE5RQp3+Ya3V+bxuw+38J3hXXVNdpEopXCXf5O2vYifLlzD6J6t+e9vD9GQ\nR5EopXCXr+3YV8rMF9Pp0qoxf7xpBIn1tXuIRCt9egWAksMVTH8hDQfMmzaSlk0SvS5JRM6Awl0o\nr/Qz6+UMcooO88cbR9CzbVOvSxKRM6Rx7nHOOcdDb2fyr637+M33hjK6VxuvSxKRWqAj9zj3zKdb\neSM9lzvH9ebbw7t6XY6I1BKFexxbllnAY3/dyFVDO+sWeSIxRuEep1bl7Oeu11cxvHtL5l5zloY8\nisQYhXscyi0+zA/mp9O+RUOeuzmVRg0SvC5JRGqZTqjGmYNHKpjxQjpHK30smDmaNs0ael2SiISB\nwj2O+PyOO19bSdaeQ8yfPore7Zt7XZKIhIm6ZeLIr97bwMeb9vCLyYM4r09br8sRkTBSuMeJN9Jz\neO4f25h6Tg9uHNPD63JEJMwU7nEgbXsRDy7O5LzebXn4yoFelyMidUDhHuNyig4z66UMurZqwlPX\nD6e+7n8qEhf0SY9hh45WcuuL6VT4/PxpaipJTXT/U5F4odEyMcrvd/xkwSq2FB7ihekjSWnXzOuS\nRKQO6cg9Rs19fxMfbtjNw1cM4Pw+7bwuR0TqmMI9Bi1emcvTn2Rz/ejuTB2b7HU5IuKBkMLdzCaa\n2SYzyzKz+2tYf7eZrTezNWb2kZlprJ1HVuws5r63MhnTqzW/mDxI14wRiVMnDXczSwCeAiYBA4Hr\nzKz6eLqVQKpz7ixgIfB4bRcqJ5e3v4yZL2bQKakRT98wggYaGSMSt0L59I8CspxzW51z5cACYErV\nBs65j51zh4OLXwC6MHgdO1xeya3z0zla4ePPU1Np1VS3yROJZ6GEexcgp8pybvC545kBvFfTCjOb\naWbpZpa+Z8+e0KuUE/L7HXe/vpqNuw7wh+uH6ZoxIhJSuNfUaetqbGh2I5AKzK1pvXPuWedcqnMu\ntV07jeCoLb/7cDN/XbeLBy4fwMX92ntdjohEgFDGuecC3aosdwXyqzcyswnAg8CFzrmjtVOenMyS\n1fn84W9ZfC+1KzPO6+l1OSISIUI5ck8D+phZTzNLBK4FllRtYGbDgD8Ck51zhbVfptRkdc5+7n1z\nNaOSW/PLq4doZIyIfO2k4e6cqwRmA8uBDcAbzrl1ZjbHzCYHm80FmgFvmtkqM1tynJeTWrKr5Ai3\nvphOu+YNefrG4STW18gYEfk/IV1+wDm3DFhW7blHqjyeUMt1yQmUlfuY+VI6pUcreXHGWN1NSUS+\nQdeWiTLOOe5duJrMvBKeuymV/h1beF2SiEQg/S0fZf73k2yWringvon9mTCwg9fliEiEUrhHkX9u\n2csT72/iqqGdue2CXl6XIyIRTOEeJfL3l3HngpWktGvGr76tkTEicmIK9yhwtNLHD19ZQXmln2du\nGkHThjpVIiInppSIAo8uXc/qnP08c+Nw3XRDREKiI/cIt2hFLi9/sZPbLujFxMGdvC5HRKKEwj2C\nbSg4wAOLA9dmv/eyfl6XIyJRROEeoUrKKpj1cgZJjRvwP9cNp76uzS4ip0B97hHI73f8xxuryCsu\n4/XbxtCuuWagisip0eFgBHr602w+3FDIQ1cMYESP1l6XIyJRSOEeYY5NVJo8tLNubi0ip03hHkGO\nTVTq3b4Zv/qOJiqJyOlTuEeIf5uodOMImiTqdIiInD4lSISoOlGplyYqicgZ0pF7BHgrIzhR6UJN\nVBKR2qFw99j6/MBEpXN6teHeSzVRSURqh8LdQyVlFfzwlQxaNmnAH64bpolKIlJr1OfuEU1UEpFw\n0qGiRzRRSUTCSeHuAU1UEpFwU7jXsbzgRKU+7ZtropKIhI3CvQ6VlFUw/fmvqKj08/SNwzVRSUTC\nRulSR8or/cx6KYNte0uZP32UJiqJSFgp3OuAc4773lrDv7bu47ffH8rY3m29LklEYpy6ZerAE+9v\nZvHKPO65tC/fGtbV63JEJA4o3MPs1S938uTHWVw3qhu3X9zb63JEJE4o3MPo442FPPzOWi7u145H\npwzWyBgRqTMK9zDJzC3h9ldXMKBTc568XvdAFZG6pcQJg5yiw0x/IY1WTRKZN20kTRvqvLWI1C2l\nTi0rOVzBtOe/orzSx4KZo2nfvJHXJYlIHArpyN3MJprZJjPLMrP7a1h/gZmtMLNKM7um9suMDkcr\nfdz6Ujo5RWU8d3Mqvds397okEYlTJw13M0sAngImAQOB68xsYLVmO4FpwKu1XWC0CFzlcTVfbSvi\n198byuhebbwuSUTiWCjdMqOALOfcVgAzWwBMAdYfa+Cc2x5c5w9DjVHhseUbWbqmgPsn9Wfy0M5e\nlyMicS6UbpkuQE6V5dzgc6fMzGaaWbqZpe/Zs+d0XiIivfiv7fzx063cNKYHt13Qy+tyRERCCvea\nBme703kz59yzzrlU51xqu3btTuclIs4H63fz8yXrmDCgPf951UCNZReRiBBKuOcC3aosdwXyw1NO\ndFmVs587XlvBkC5Juk2eiESUUNIoDehjZj3NLBG4FlgS3rIi3459pcx4IY12zRvy52kjdfleEYko\nJw1351wlMBtYDmwA3nDOrTOzOWY2GcDMRppZLvBd4I9mti6cRXutqLScac+n4XOOF6aPom0z3f9U\nRCJLSIebzrllwLJqzz1S5XEage6amHekwsetL6aTt7+MV38wmhRdl11EIpA6iU9ByeEKbp73FSt2\nFvO7759NarJubC0ikUkdxSHK21/GtHlfsX1fKb/7/tlcPqST1yWJiByXwj0E6/MPMO35ryir8DH/\nllGMTdGdlEQksincT+KfW/Yy6+UMmjeqz8JZY+nXUdeLEZHIp3A/gUUrcvnpwjX0bt+M56ePpFNS\nY69LEhEJicK9Bs45/veTbOYu38Q5vdrwx5tH0KJRA6/LEhEJmcK9mkqfn/9cso5XvtzJlLM7M/ea\noSTW16AiEYkuCvcqysp93PHaCj7cUMisC1P46WX9qFdP14oRkeijcA/ad+goM+anszp3P3OmDOLm\nc5K9LklE5LQp3AlcJ2bqvK8oKDnCMzeO4LJBHb0uSUTkjMR9uK/K2c+MF9LwO8ert45hRI9WXpck\nInLG4jrcP9qwm9tfXUG75g2ZP30UvXSdGBGJEXEb7q98uYOH317LoM5JzJs2knbNdWVHEYkdcRfu\nzjmeeH8zT36cxUX92vHU9cNp2jDuNoOIxLi4SrUNBQeY8+56/rV1H99P7cb/+9Zg3T1JRGJSXIR7\nUWk5v/lgE69+uZMWjRvwy6sHc8Po7rrfqYjErJgO9wqfn5e/2MFvP9hMabmPm89J5icT+tCySaLX\npYmIhFXMhvunm/fw6NL1ZBUe4vw+bXn4yoH07aArOopIfIi5cN+2t5RfLl3PRxsL6dGmCc/dnMqE\nAe3VBSMicSVmwv3AkQqe/FsWz3+2jYb1E/jZpP5MOzeZhvUTvC5NRKTORX24+/yOhRk5zF2+iX2l\n5Xx3RFfuuawf7Zs38ro0ERHPRHW4p20v4hfvrmNt3gFG9GjFvGkjOatrS6/LEhHxXFSGe97+Mn71\n3kbeXZ1Pp6RG/P7as5k8tLP61UVEgqIu3N9Iy+GRJWtxDu4c34dZF/aiSWLU/TNERMIq6lIxuW1T\nxvfvwM8u70/XVk28LkdEJCJFXbiP6tmaUT1be12GiEhE04VVRERikMJdRCQGKdxFRGKQwl1EJAYp\n3EVEYlBI4W5mE81sk5llmdn9NaxvaGavB9d/aWbJtV2oiIiE7qThbmYJwFPAJGAgcJ2ZDazWbAZQ\n7JzrDfwWeKy2CxURkdCFcuQ+Cshyzm11zpUDC4Ap1dpMAeYHHy8ExpuuBSAi4plQJjF1AXKqLOcC\no4/XxjlXaWYlQBtgb9VGZjYTmBlcPGRmm06naKBt9deOMKrvzKi+MxfpNaq+09cjlEahhHtNR+Du\nNNrgnHsWeDaE9zxxQWbpzrnUM32dcFF9Z0b1nblIr1H1hV8o3TK5QLcqy12B/OO1MbP6QBJQVBsF\niojIqQsl3NOAPmbW08wSgWuBJdXaLAGmBh9fA/zNOfeNI3cREakbJ+2WCfahzwaWAwnAPOfcOjOb\nA6Q755YAfwZeMrMsAkfs14azaGqhayfMVN+ZUX1nLtJrVH1hZjrAFhGJPZqhKiISgyI63CN5ZqyZ\ndTOzj81sg5mtM7Mf19DmIjMrMbNVwa9H6qq+4PtvN7PM4Hun17DezOwPwe23xsyG12Ft/apsl1Vm\ndsDMflKtTZ1vPzObZ2aFZra2ynOtzewDM9sS/N7qOD87Ndhmi5lNralNGGqba2Ybg/9/i82sxpsI\nn2xfCHONPzezvCr/j5cf52dP+HkPY32vV6ltu5mtOs7P1sk2rDXOuYj8ItC/nw30AhKB1cDAam1+\nBDwTfHwt8Hod1tcJGB583BzYXEN9FwFLPdyG24G2J1h/OfAegaGsY4AvPfy/3gX08Hr7ARcAw4G1\nVZ57HLg/+Ph+4LEafq41sDX4vVXwcas6qO1SoH7w8WM11RbKvhDmGn8O3BPCPnDCz3u46qu2/gng\nES+3YW19RfKRe0TPjHXOFTjnVgQfHwQ2EJjMFU2mAC+6gC+AlmbWyYM6xgPZzrkdHrz3v3HO/Z1v\nDuOtup/NB66u4UcvAz5wzhU554qBD4CJ4a7NOfe+c64yuPgFgaHKnjnO9gtFKJ/3M3ai+oLZ8T3g\ntdp+Xy9EcrjXNDO2enj+28xY4NjM2DoV7A4aBnxZw+pzzGy1mb1nZoPqtLDARLL3zSwjODu4ulC2\ncV24luN/oLzcfsd0cM4VQOCXOtC+hjaRsC1vIfCXWE1Oti+E2+xg19G843RrRcL2Ox/Y7Zzbcpz1\nXm/DUxLJ4V5rM2PDycyaAW8BP3HOHai2egWBroahwP8Ab9dlbcC5zrnhBC76druZXVBtfSRsv0Rg\nMvBmDau93n6nwtNtaWYPApXAK8dpcrJ9IZyeBlKAs4ECAl0f1Xm+LwLXceKjdi+34SmL5HCP+Jmx\nZtaAQLC/4pxbVH29c+6Ac+6itiilAAAB2ElEQVRQ8PEyoIGZta2r+pxz+cHvhcBiAn/6VhXKNg63\nScAK59zu6iu83n5V7D7WXRX8XlhDG8+2ZfDk7ZXADS7YOVxdCPtC2DjndjvnfM45P/Dccd7b030x\nmB/fBl4/Xhsvt+HpiORwj+iZscH+uT8DG5xzvzlOm47HzgGY2SgC23tfHdXX1MyaH3tM4MTb2mrN\nlgA3B0fNjAFKjnU/1KHjHi15uf2qqbqfTQXeqaHNcuBSM2sV7Ha4NPhcWJnZROA+YLJz7vBx2oSy\nL4Szxqrncb51nPcO5fMeThOAjc653JpWer0NT4vXZ3RP9EVgNMdmAmfRHww+N4fAjgzQiMCf81nA\nV0CvOqztPAJ/Nq4BVgW/LgdmAbOCbWYD6wic+f8CGFuH9fUKvu/qYA3Htl/V+ozAtfqzgUwgtY7/\nf5sQCOukKs95uv0I/KIpACoIHE3OIHAe5yNgS/B762DbVOBPVX72luC+mAVMr6Pasgj0VR/bB4+N\nHusMLDvRvlCH2++l4P61hkBgd6peY3D5G5/3uqgv+PwLx/a7Km092Ya19aUZqiIiMSiSu2VEROQ0\nKdxFRGKQwl1EJAYp3EVEYpDCXUQkBincRURikMJdRCQGKdxFRGLQ/wcdPALp/PoIOgAAAABJRU5E\nrkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = [i for i in range(20)]\n",
    "plt.plot(epochs,loss_vec)\n",
    "plt.figure()\n",
    "plt.plot(epochs,batch_accuracy)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.04100000027101487,\n",
       " 0.11811999994330108,\n",
       " 0.22264000087045133,\n",
       " 0.3080000026896596,\n",
       " 0.3735200010240078,\n",
       " 0.42231999561190603,\n",
       " 0.45748000115156173,\n",
       " 0.48492000162601473,\n",
       " 0.5053600046038628,\n",
       " 0.5198799988627434,\n",
       " 0.5307199957966805,\n",
       " 0.5388399991393089,\n",
       " 0.5451200005412101,\n",
       " 0.5495599994063377,\n",
       " 0.5535199978947639,\n",
       " 0.5563999989628792,\n",
       " 0.5592800024151802,\n",
       " 0.561280001103878,\n",
       " 0.5628399977087974,\n",
       " 0.5639999958872796]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
